%%
%% This is file `sample-xelatex.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `sigconf')
%%
%% IMPORTANT NOTICE:
%%
%% For the copyright see the source file.
%%
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-xelatex.tex.
%%
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%%
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%% The first command in your LaTeX source must be the \documentclass command.
\documentclass[sigconf]{acmart}
\newtheorem{assumption}{Assumption}

%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmcopyright}
\copyrightyear{2018}
\acmYear{2018}
\acmDOI{10.1145/1122445.1122456}

%% These commands are for a PROCEEDINGS abstract or paper.
\acmConference[Woodstock '18]{Woodstock '18: ACM Symposium on Neural
  Gaze Detection}{June 03--05, 2018}{Woodstock, NY}
\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
  June 03--05, 2018, Woodstock, NY}
\acmPrice{15.00}
\acmISBN{978-1-4503-XXXX-X/18/06}


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}

%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{ECDSA}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.


%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.


%%
%% The abstract is a short summary of the work to be presented in the
%% article.


%% A "teaser" image appears between the author and affiliation
%% information and the body of the document, and typically spans the
%% page.


%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Our contribution}
%We first extract on average $156.2$ bits of information from the Double-Add-Invert Chain per signatuare for the 256-bit elliptic curve. Then we translate the recovery of the secret key to the problem of solving the pretty short vector  in some “newly constructed” lattice.  The newly constructed lattice is more “efficient” as  it is much easier to find the short vector by the lattice reduction algorithm comparing to the constructed lattice in \cite{FWC16} given the same information, which makes 2 signatures, which attains the optimal bound, are enough to recover the secret key. Lastly, some new techniques are introdued to improve the success probability to $24.5\%$ for recover the secrete key in less than half an hour for only 2 signature.

We first extract on average $156.2$ bits of information from the Double-Add-Invert Chain per signatuare for the 256-bit elliptic curve. Then a novel method is introduced to construct the related lattice, in which, short vectors are  much easier to be found by the lattice reduction algorithm comparing to the constructed lattice in \cite{FWC16}. As a result, we can recover the secret key with only 2 signatures , which attains the optimal bound. Lastly, some new techniques are introdued to improve the success probability.
We applied our attack to the secp256K1 curve. 3 signatures is enough to recover the secret key with a high success probablity no less than $73\%$. When we have only two signatures, we can recover the secret key with a success probability no less than $24.3\%$.

\section{ Extracting more Information }
      Assuming we get a perfect {\bf Double-Add-Invert Chain}. Suppose in  Double-Add-Invert Chain, there are $l$ numbers of $''A''$s, whose positions are separately $\lambda_i$($1\leq i\leq l$) counted from the lower index. So we can easiy have
 $$k=\sum\limits_{i=0}^{l-1}  k^{'}_i 2^{\lambda_i}$$
 where $$k^{'}_i\in\{-7,-5,-3,-1,1,3,5,7\}.$$

    On the other hand, from the Invert chain, we can easily know whether the $k^{'}_i$ is a positive integer or a negative integer. Suppose  $k^{'}_i=(-1)^{h_i} k^{*}_i$ , where $(-1)^{h_i}$ is the sign of $k^{'}_i$  which is known, $k^{*}_i\in \{1,3,5,7\}$. Write $ k^{*}_i=2k_i+1$ , where $k_i\in \{0,1,2,3\}$. Then we have
 \begin{equation}
  \begin{array}{lll}{\label {KKK}}
 k&=&\sum\limits_{i=0}^{l-1} (-1)^{h_i} k^{*}_i 2^{\lambda_i}  \\
 &=& \sum\limits_{i=0}^{l-1} (-1)^{h_i}(2k_i+1)2^{\lambda_i}  \\
 &=&\bar{k}+\sum\limits_{i=0}^{l-1} (-1)^{h_i}k_i2^{\lambda_i+1}
  \end{array}
 \end{equation}
where $\bar{k}=\sum\limits_{i=0}^{l-1}{(-1)^{h_i}2^{\lambda_i} }$, $h_i$, $\lambda_i$ are known and the only unknowns are $k_i\in\{0,1,2,3\}$.

 %%    As we can know whether the “Invert” operation was  %%done or not ,which means the difference of the sign of %% $k_i$ and $k_{i+1}$ is known($0\leq i\leq l-1$). We %suppose the sign of $k_0$ is $(-1)^{h_0}$. Sequencely %we can easily get  the sign of $k_i$  which can be written %as $(-1)^{h_0+h_i}$, where $h_0\in \{0,1\}$ is unkown %and $h_i\in \{0,1\}$ ($1\leq i\leq l$)are known. So we have
    % $$k=\sum\limits_{i=0}^{l-1}  (-1)^{h_i} k^{`}_i %2^{\lambda_i}$$
  %       and the sign of $(-1)^{h_i}$,which can be viewed as %known.

    It is known that there are approximately $(\lceil logq\rceil +1)/(\omega+2)-1=50.4 $ non-zero digits in the Double-Add-Invert Chain when  $\omega=3$. From Eq.(\ref{KKK}), there
    are approximatley 50.4*2= 100.8 bits being unkown, which means the known bits are about $257-100.8=156.2$ on avarage. In theory, we need at least two signatures to recover the $256$-bit secrete key, as $2$ is the least integer $m$ such that $m\cdot 156.2 >256$.

    From above we can see, with our new Double-Add-Invert Chain, we can extract  on average $156.2$ bits of information per signatuare for the 256-bit elliptic curve, which is about $1.5$ times of the number of bits in \cite{FWC16} .
    In the next subsection, we will show that we can recover the secret key with only $2$ signatures which attains the optimal bound.



  \section{Find the target vector with new lattice}
  Similar to \cite{FWC16}, we first translate the problem of recovering ECDSA secret key to the EHNP Problem. Then we further translate it to the problem of solving approximate SVP Problem using lattice reduction algorithm.

     On the othe hand, in order to achieve the optimal bound, i.e., we only need $2$ signatures and the corresponding Double-Add-Invert Chain to recover the secret key. Some new ideas and Techniques are introduced which aims both reducing the attacking time and increasing the success probability.

      First and most importantly, we  observe the components of target vector in \cite{FWC16} isn't balanced,  so we reconstruct the lattice in \cite{FWC16} which reduces the length of target vector much, epecially when the number of possible values of unkown $k_i$ is small.

     Then, we guess some $k_{i,j}$ to reduce the dimension of lattice and improve the success probability. Finally, we observe that BKZ will recover different samples with different $\delta$'s, therefor, we provide some plausible reasonable $\delta$'s and use them to improve success probability.


     We applied our attack to the secp256K1 curve. 3 signatures is enough to recover the secret key with a high success probablity not less than $73\%$. When we have only two signatures, we can recover the secret key with a success probability no less than $24.3\%$.

       \subsection {Reduction to EHNP Problem}
  Assuming we have a  signature pair $(r,s)$ of messgage $m$. Then we have the equation
  \begin{equation}\label {SigEqu}
  \alpha r-sk+H(m)=0\mod q.
  \end{equation}
  Substitue (\ref{SigEqu}) with Equation ({\ref{KKK}}), we can have that there exists an $h\in \mathbb{Z}$ such that
\begin{equation}\label{SigEqu2}
\alpha r-\sum\limits_{i=1}^l((-1)^{h_i}2^{\lambda_i+1}s)k_i-(s\bar{k}-H(m))+hq=0.
\end{equation}
where $\alpha, k_i (1\leq i \leq l)\text{ and } h$ is unknown.

Assuming we got $u$ signature pairs $(r_i,s_i)$ of different messages $m_i$($1\leq i\leq u$) with the same secret key $\alpha$.
Suppose we get the Double-ADD-Invert Chain of each ephemeral key. From  (\ref{SigEqu2}) we can easliy have
 \begin{equation}
\begin{cases}
\label{SigEqu2}
\alpha r_1-\sum\limits_{j=0}^{l_1-1}((-1)^{h_{1,j}}2^{\lambda_{1,j}+1}s_1)k_{1,j}-(s_1\bar{k}_1-H(m_1))+h^{'}_1q=0  \\
\qquad\qquad\qquad\quad\vdots\\
\alpha r_i-\sum\limits_{j=0}^{l_i-1}((-1)^{h_{i,j}}2^{\lambda_{i,j}+1}s_i)k_{i,j}-(s_i\bar{k}_i-H(m_i))+h^{'}_iq=0  \\
\qquad\qquad\qquad\quad\vdots\\
\alpha r_u-\sum\limits_{j=0}^{l_u-1}((-1)^{h_{u,j}}2^{\lambda_{u,j}+1}s_u)k_{u,j}-(s_u\bar{k}_u-H(m_u))+h^{'}_uq=0
\end{cases}
\end{equation}
where $l_i$ is the number of non-zero digits of the $i$-th ephemeral key and $(-1)^{h_{i,j}}k_{i,j}$ is the $j$-th non-zero digit in the $i$-th signature, $\lambda_{i,j}$ is its position, $\bar{k}_i=\sum\limits_{j=0}^{l_i-1}(-1)^{h_{i,j}}2^{\lambda_{i,j}} \mod q$ and $\alpha, h^{'}_i, k_{i,j}$ are unknown elements in the equations.  \\


Given Equation (\ref{SigEqu2}), find $0<\alpha<q$ and $0\leq k_{i,j}\leq 2^{w-1}-1$. We denote this problem DSA-EHNP.

  \subsection {Balancing the target vector}

     Next we will translate the DSA-EHNP problem to the problem of finding the short vector of a related lattice. Then we can find the secret key from the short vector. Comparing to the constructed lattice \cite{FWC16},  the determinant of our new lattice is larger, while the target vector is shorter and more balanced, which makes the lattice reduction algorithmn easier to find the target vector.

     Notice that we have $k_{i,j}\in \{0,1,\cdots, 2^{w-1}-1\}$. For $1\leq i \leq u$ and $1\leq j\leq l_i$, denote $\gamma_{i,j}=(-1)^{h_{1,j}}2^{\lambda_{1,j}+1}s_1r_i\mod q$, $c_{i,j}=(-1)^{h_{i,j}+1}2^{\lambda_{i,j}+1}s_ir_1\mod q$, $\beta_i=r_1(H(m_i)-s_i\bar{k}_i)-r_i(H(m_1)-s_1\bar{k}_1) \mod q$. We can construct a lattice $L$ spanned by the lines of the following matrix $B$ in Equation (\ref{SigEqu3}) which is obtained by eliminating $\alpha$ in Equation (\ref{SigEqu2}). The parameter $\delta$ which will be discussed in section \ref{section3.3} is  a proper value.

  \begin{equation}
    \label{SigEqu3}
     \textbf{B}=\left(\begin{matrix}

\begin{smallmatrix}
 q&&&&&&&&&&\\
&\ddots&&&&&&&&&\\
&&q&&&&&&& &\\
\gamma_{2,1}&\cdots&\gamma_{\mu-1,1}&\frac{\delta}{3}&&&&&&\\
\vdots&&&&\ddots&&&&&\\
\gamma_{2,l_1}&\cdots&\gamma_{\mu-1,l_1}&&&\frac{\delta}{3}&&&&&\\
c_{2,1}&&&&&&\frac{\delta}{3}&&&&&&\\
\vdots&&&&&&&\ddots&&\\
c_{2,l_2}&&&&&&&&\frac{\delta}{3}&&&&&\\
&\ddots&&&&&&&&\ddots&&&&\\
&&c_{\mu,1}&&&&&&&&\frac{\delta}{3}&&&\\
&&\vdots&&&&&&&&&\ddots&&\\
&&c_{\mu,l_\mu}&&&&&&&&&&\frac{\delta}{3}&\\
\beta_2&\cdots&\beta_u&\frac{\delta}{2}&\cdots&\frac{\delta}{2}&\frac{\delta}{2}&\cdots& \frac{\delta}{2}&\cdots&\frac{\delta}{2}&\cdots&\frac{\delta}{2}&\frac{\delta}{2}\\

\end{smallmatrix}&

\end{matrix}\right)
  \end{equation}
  Suppose $h_i=r_1h_i^{'}-r_ih_1^{'}$, it is easy to check there exists
  $$
  \begin{array}{lll}
  \textbf{w}&=&(h_2,\cdots,h_{\mu},k_{1,1},\cdots,k_{1,l_1},\cdots,k_{u,1},\cdots,k_{u,l_u},1)\textbf{B}\\
  &=&(0,\cdots,0,\frac{k_{1,1}}{3}\delta-\frac{\delta}{2},\cdots,\frac{k_{1,l_1}}{3}\delta-\frac{\delta}{2},\cdots, \\
  &&\frac{k_{u,1}}{3}\delta-\frac{\delta}{2},\cdots,\frac{k_{u,l_u}}{3}\delta-\frac{\delta}{2},\frac{\delta}{2})\in L(\textbf{B}),
  \end{array}
  $$
and the Euclid norm of the vector $\textbf{w}$ satisfys
$\|\textbf{w}\|\leq \frac{\delta}{2}\sqrt{n-u+1}$, where $n$ is the dimension of the lattice, i.e., $n=\sum\limits_{i=1}^{u}l_i+u$.

The determinant of lattice $L(\textbf{B})$ is $\|L\|=\frac{1}{2}q^{u-1}\cdot {\delta}^{n-u+1}(\frac{1}{3})^{n-u}$. The target vector $\textbf{w}$ may not be the shortest vector, however, if we choose a appropriate value of $\delta$, the target vector $\textbf{w}$ which will be a pretty short vector which can be found by lattice reduction algorithm(\cite{LLL82}, \cite{SE94}, \cite{CN12}, \cite{ADH+19}), thus, the secret key $\alpha$ can be recovered.

 {\bf Comparing with the constructed lattice in \cite{FWC16}.}  The constructed lattice is similar to the lattice in \cite{FWC16} with two refinements. Firstly, we notice that if the diagonal entries of the matrix from line $\mu$ to line $n-1$ are  $\frac{\delta}{7}$ instead of  $\frac{\delta}{8}$ in \cite{FWC16}, which not only make the  determinant more larger , but also make the target vector more balanced. On the other word, $-\frac{\delta}{2}\leq \frac{k_{i,j}}{8}\delta-\frac{\delta}{2}\leq \frac{3\delta}{8}$ if $0\leq k_{i,j}\leq 7$,which will be slightly reduced. While if we subtititue $\frac{k_{i,j}}{8}$ by $\frac{k_{i,j}}{7}$, we have  $-\frac{\delta}{2}\leq\frac{k_{i,j}}{7}\delta-\frac{\delta}{2}\leq \frac{\delta}{2}$ if $0\leq k_{i,j}\leq 7$. In that case, the determinant of the new lattice is $(\frac{8}{7})^{n-u}$ times as large as the old lattice, while the expected length of the target vector will increase to $\sqrt{\frac{96}{77}}$ times, therefore, $\frac{\|\textbf{w}\|}{(|det(L)|)^{1/n}}$ will decrease.  Secondly, since we can get more information of the emphemeral key, i.e, for the lattice in \cite{FWC16}, we have $0\leq d_{i,j}\leq 7$, while now we have $0\leq d_{i,j}\leq 3$. We can further change the diagonal entries of the matrix from line $\mu$ to line $n-1$ from $\frac{\delta}{7}$ to  $\frac{\delta}{3}$, Which increase the absolute value of the determinent of the lattice very much, however, slightly increase the length of the target vector. Generally, the smaller $\frac{\|\textbf{w}\|}{(|det(L)|)^{1/n}}$ is, the easier the lattice reduction algorithmn is to find the target vector. Therefore, we can find the target vector more easily when we use the newly constructed lattice.

The following experiments prove the validity of balancing. Firstly, we do tests using the way in \cite{FWC16} and the above refinements with 3 signatures, we can see the success probability is $73\%$, which is very high. Therefore, we try to recove the secret key with 2 signature in the following section.  Our experiments in line 3 and line 4 and the following sections are based on the skills in \cite{FWC16} without merging which will drop the probability in experiment with $2$ signatures. The results in Table \ref{table1} shows that balancing can effectively improve the success probability.
 \begin{table}[!hbp]
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
$\mu$&samples&balance&block&probability&time(s)\\
\hline
3&1000&Yes&30&73\%&34.7\\
\hline
2&1000&No&30&0\%&126.7\\
\hline
2&1000&Yes&30&5.7\%&154.0\\
\hline

\end{tabular}
\caption{The advantage of balancing}\label{table1}
"samples" represents the number of samples, "block" is the blocksize of BKZ and "time(s)" is the time of BKZ on each sample.
\end{table}



\subsection{Guessing some $k_{i,j}$’s}\label{section3.3}
In this section, we will analyse the way of guessing which can balances the success probability and time complexity of BKZ.
Considering that the set of $k_{i,j}$ is small, we guess the value of $k_{i,j}$ to improve the success probability. Each $k_{i,j}$ has 2 bits information, thus, the expection of the number of guessing to gain the right $k_{i,j}$ is $\frac{1}{4}(1+2+3+4)=\frac{5}{2}$. Every time we guess $k_{i,j}$, the expected time complexity will increase to $\frac{5}{2}$ times and the dimension will decrease 1.

Guessing will increase the time complexity, however, it can also improve success probability. From experiment results based on the skill of balancing in Table \ref{table2}, we can observe that the time complexity will increase to 3.7/34.2 times when we guess 2/4 $k_{i,j}$'s, while the success probability will expand 2.7/4.4 times respectively.
Moreover, comparing to the way of not using guessing with larger blocksize(35), the skill of guessing with blocksize(30) will be more efficient. Therefore, in the next section \ref{3.4}, we will further discuss how to improve the success probability based on the technology of balancing and guessing.

\begin{table}[!hbp]
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
$\mu$&samples&guessing&block&$\delta$&probability&time(s)\\
\hline
2&1000&2&30&$\delta_0$&15.3\%&566.7\\
\hline
2&1000&4&30&$\delta_0$&25.3\%&5260.4\\
\hline
2&1000&0&35&$\delta_0$&9\%&3387\\
\hline
\end{tabular}
\caption{Balancing and guessing}\label{table2}
"guessing" represents the number of $k_{i,j}$ guessed, "$\delta_0$" will be explained in section \ref{3.4}.
\end{table}


\subsection{Choosing different $\delta$’s}\label{3.4}
Finally, based on the experimental phenoenas: 1. the success probability will change with different $\delta$'s, 2. different samples  will be recovered if we select different $\delta$'s, we  analyse how to select the parameter $\delta$ and utilize different $\delta$'s to improve the success probability.

If the target vector can be found by lattice reduction algorithm, the following two conditions need to be satisfied: 1. the target vector is enough short. 2. the BKZ can recover lattice vector as long as the target vector.  Condition 1 can be achieved by balancing and selecting a appropriate $\delta$. When condition 1 is satisfied, condition 2 can be solved by adjusting the BKZ parameter $\beta$.

We observe some situations that lattice can produce vectors set $T$ which are more shorter than target vector. Based on these observations, we expect to reduce the size of $T$ by selecting suitable parameter $\delta$. The followings are some heuristic $\delta$'s.

1. Choose $\delta_0=\frac{2}{\sqrt{n-\mu+1}}$ to guarantee any lattice vector $\textbf{a}$ which exists $\textbf{a}_i\neq0$ for $i\in[0,m-1]$ is much longer than target vector $\textbf{w}$. Beacuse, for $i\in[0,m-1]$, when $\textbf{a}_i\neq0$, $|\textbf{a}_i|\geq1$ then $\|\textbf{a}\|\geq 1\geq\|\textbf{w}\|$. Therefore, by setting $\delta=\frac{2}{\sqrt{n-\mu+1}}$, the size of set $T$ will decrease.

2. We try some other $\delta$'s, just like $2\delta_0,\frac{\delta_0}{2}$ and so on. We notice that different $\delta$'s may recover different samples. Therefore, for a same sample, if we choose several $\delta$'s to construct different lattices, we can improve the success probability.


Of course, this method will enlarge the time complexity, however, compared with the improvement of success probability, the incresea of time complexity is acceptable. The related data which is based on the ways of balancing and guessing and different $\delta$'s can be found in Table \ref{table3}. We can see the probability will increase to $24.3\%$ when using 3 different $\delta$'s, however, the time complexity will approximately increase by 2 times. Compared with the experiment using guessing 4 $k_{i,j}$'s in Talbe \ref{table2}, the way of combining guessing 2 $k_{i,j}$'s and different $\delta$'s is more efficient.

\begin{table}[!hbp]
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
$\mu$&samples&guessing&block&$\delta$&probability&time(s)\\
\hline
2&1000&2&30&$\delta_0$&15.3\%&566.7\\
\hline
2&1000&2&30&$\frac{\delta_0}{2}$&14.6\%&550.0\\
\hline
2&1000&2&30&$2\delta_0$&13\%&516.7\\
\hline
total&&&&&24.3\%&1633.4\\
\hline

\end{tabular}
\caption{Balancing, guessing and different $\delta$'s}\label{table3}
The last line records the total success probability and the average time using three different $\delta$‘s .
\end{table}







\begin{thebibliography}{21}

\bibitem{FWC16}
Shuqin Fan, Wenbo Wang, and Qingfeng Cheng. Attacking OpenSSL implementation of ECDSA with a few signatures. InCCS, pages 1505–1515.ACM, 2016.
\bibitem{LLL82}
A.K. Lenstra, Jr. Lenstra, H.W., and L. Lova ́sz. Factoring polynomials with rational coeffi- cients. Mathematische Annalen, 261(4):515–534, 1982.
\bibitem{SE94}
Claus Peter Schnorr and M. Euchner. Lattice basis reduction: Improved practical algorithms and solving subset sum problems. Math. Program., 66:181–199, 1994.
\bibitem{CN12}
Yuanmi Chen and Phong Q. Nguyen. BKZ 2.0: Better lattice security estimates (full version). {\url{http://www.di.ens.fr/~ychen/research/Full_BKZ.pdf}}, 2012.

\bibitem{ADH+19}
Martin Albrecht, L´eo Ducas, Gottfried Herold, Elena Kirshanova, Eamonn Postlethwaite, and Marc Stevens. The general sieve kernel and new records in lattice reduction. In EUROCRYPT, 2019.


\end{thebibliography}


\end{document}
\endinput
%%
%% End of file `sample-xelatex.tex'.
